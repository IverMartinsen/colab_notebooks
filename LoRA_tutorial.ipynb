{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPw7c51cRg2UWH52cmrfR9D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IverMartinsen/ColabNotebooks/blob/main/LoRA_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fine-tuning with LoRA**\n",
        "This script is mostly copy-pasted from this: https://huggingface.co/docs/peft/main/en/task_guides/image_classification_lora"
      ],
      "metadata": {
        "id": "k77EnQOqzWNA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install dependencies**"
      ],
      "metadata": {
        "id": "dqYPPF6aLV2J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wz7lzd5oLMEF"
      },
      "outputs": [],
      "source": [
        "pip install -q transformers accelerate evaluate datasets peft"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import modules"
      ],
      "metadata": {
        "id": "AbiRG3rX_VMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "import accelerate\n",
        "import peft\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from transformers import (\n",
        "    AutoImageProcessor,\n",
        "    AutoModelForImageClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "from torchvision.transforms import (\n",
        "    CenterCrop,\n",
        "    Compose,\n",
        "    Normalize,\n",
        "    RandomHorizontalFlip,\n",
        "    RandomResizedCrop,\n",
        "    Resize,\n",
        "    ToTensor,\n",
        ")\n"
      ],
      "metadata": {
        "id": "GynARVZl8UYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load data (this will take ~5mins).**\n",
        "\n",
        "For documentation about the Dataset class: https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset"
      ],
      "metadata": {
        "id": "LNF0OvJJLf5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"food101\", split=\"train[:5000]\")"
      ],
      "metadata": {
        "id": "oJWigPvOLvk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split into train/test**"
      ],
      "metadata": {
        "id": "kPUDKSUYBlqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "splits = ds.train_test_split(test_size=0.1)\n",
        "\n",
        "train_ds = splits[\"train\"]\n",
        "val_ds = splits[\"test\"]"
      ],
      "metadata": {
        "id": "WB5DZJPz9LSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Construct preprocessing pipelines for training and validation data**"
      ],
      "metadata": {
        "id": "iIV2MJR_DD1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "\n",
        "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
        "\n",
        "train_transforms = Compose(\n",
        "    [\n",
        "        RandomResizedCrop(image_processor.size[\"height\"]),\n",
        "        RandomHorizontalFlip(),\n",
        "        ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_transforms = Compose(\n",
        "    [\n",
        "        Resize(image_processor.size[\"height\"]),\n",
        "        CenterCrop(image_processor.size[\"height\"]),\n",
        "        ToTensor(),\n",
        "        normalize,\n",
        "    ]\n",
        ")\n",
        "\n",
        "def preprocess_train(example_batch):\n",
        "    \"\"\"Apply train_transforms across a batch.\"\"\"\n",
        "    example_batch[\"pixel_values\"] = [train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
        "    return example_batch\n",
        "\n",
        "\n",
        "def preprocess_val(example_batch):\n",
        "    \"\"\"Apply val_transforms across a batch.\"\"\"\n",
        "    example_batch[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
        "    return example_batch\n",
        "\n",
        "train_ds.set_transform(preprocess_train)\n",
        "val_ds.set_transform(preprocess_val)\n"
      ],
      "metadata": {
        "id": "am736RlGMX3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the pretrained Vision Transformer**"
      ],
      "metadata": {
        "id": "_p131EG7EJaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a simple string-to-int dict mapping for labeling the data\n",
        "labels = ds.features[\"label\"].names\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = i\n",
        "    id2label[i] = label\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True,  # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n",
        ")\n"
      ],
      "metadata": {
        "id": "EaJQlCfxL38i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply a LoRA wrapper to the model**"
      ],
      "metadata": {
        "id": "j6GLWatiEywb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"query\", \"value\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    modules_to_save=[\"classifier\"],\n",
        ")\n",
        "model = get_peft_model(model, config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "mPRp6gD_9hoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set training arguments**\n",
        "\n",
        "For documentation about the Trainer class: https://huggingface.co/docs/transformers/main_classes/trainer#api-reference%20][%20transformers.Trainer"
      ],
      "metadata": {
        "id": "xoEsW9nRHYe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"my-finetuned-lora-food101\",\n",
        "    remove_unused_columns=False,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-3,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=4,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    fp16=True,\n",
        "    num_train_epochs=5,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    push_to_hub=False,\n",
        "    label_names=[\"labels\"],\n",
        ")\n",
        "\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)\n",
        "\n",
        "\n",
        "def collate_fn(examples):\n",
        "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
        "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=image_processor,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        ")\n"
      ],
      "metadata": {
        "id": "Nsl3d0ut94Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train model**"
      ],
      "metadata": {
        "id": "CRt7J0XaHeg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_results = trainer.train()"
      ],
      "metadata": {
        "id": "9IjnXcyxGs6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "H2m9Ry9dHrfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(val_ds)"
      ],
      "metadata": {
        "id": "TGoFCu9v96ma"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}